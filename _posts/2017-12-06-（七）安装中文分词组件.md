---
layout:     post
title:      （七）安装中文分词组件
author:     luohaipeng
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - elasticsearch
---
## 分词组件
elasticsearch提供了几个内置的分词器：standard analyzer(标准分词器)、simple analyzer(简单分词器)、whitespace analyzer（空格分词器）、language analyzer（语言分词器），而如果我们不指定分词器类型的话，elasticsearch默认是使用标准分词器的。那接下来我们先来看看这几种分词器的特点。  
ps：我们可以通过分词器测试api来看看每个分词器的特点，语法为：
```
POST _analyze
{
  "analyzer": "分词器类型",
  "text": "我是一个中国人，张姓在中国是大姓。"
}
```
返回的结果就是我们使用该分词器给搜索关键词分词的结果。
#### 标准分词器
测试标准分词器分词效果：  
![标准分词器](https://upload-images.jianshu.io/upload_images/10574922-d0eb6284b065ed3b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

通过测试结果我们可以发现，使用标准分词器的分词结果，是去掉标点符号，然后一个一个字符来分词，这就是我们上一章提到的中文搜索的问题，这显然不是我们想要的分词效果。那我们接着看下一个分词器。  
#### 简单分词器
测试标准分词器分词效果：  
![简单分词器](https://upload-images.jianshu.io/upload_images/10574922-c1e6c249fb993e59.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
通过上面的测试结果发现，简单分词器它是通过标点符号来分词的，如果我整个搜索关键词都没有标点符号，那么它就不能分词了，以搜索关键词原样输出，这种也不是我们想要的分词效果。
#### 空格分词器
测试空格分词器分词效果：  
![空格分词器](https://upload-images.jianshu.io/upload_images/10574922-2fa9ac8ce5530b1d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
通过测试我们发现，使用空格分词器对“我是一个中国人,张姓在中国是大姓。”搜索关键词分词，它给我们原样返回了，那顾名思义，空格分词器就是以空格来分词，而我们上面这条搜索关键词并没有空格，所以到时候这个搜索关键词就是最小的词元了。看到现在，好像上面几种分词器的分词结果都不是我们想要的。那我们接着来看最后一个分词器。
#### 语言分词器
所谓的语言分词器，其实就是elasticsearch提供的世界流行语言分词器集合，它支持的人类语言有：阿拉伯语、亚美尼亚语、巴斯克语、巴西语、保加利亚语、加泰罗尼亚语、中文、捷克语、丹麦、荷兰语、英语、芬兰语、法语、加里西亚语、德语、希腊语、北印度语、匈牙利语、印度尼西亚、爱尔兰语、意大利语、日语、韩国语、库尔德语、挪威语、波斯语、葡萄牙语、罗马尼亚语、俄语、西班牙语、瑞典语、土耳其语和泰语。  
我们可以看到中文也在它支持的范围内，那这样的话，如果我们使用语言分词器中的中文来对“我是一个中国人,张姓在中国是大姓。”关键词分词，那它的分词效果是如果呢？我们来看看：  
![中文语言分词器](https://upload-images.jianshu.io/upload_images/10574922-a739ecd9ea6f5f54.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  
我们通过上面的分词结果很遗憾的发现，即时我们使用了elasticsearch为我们提供的中文语言分词器来对中文分词，其效果也是不理想，因为从结果来看，它跟标准分词器是一样的，都是按每个中文字符来分词。  
ps：语言分词器在使用的时候是要指定该语言的英文单词的，比如中文就是chinese，英文就是english，法语就是french，如此类推...我们可以来看看一段法语的分词测试：  
![法文语言解析器](https://upload-images.jianshu.io/upload_images/10574922-73070c9cfe2ef6c1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
上面的分词结果就是法文的分词结果，我想不懂法文的人都没办法确定该分词效果如何，但是至少可以确定法文的分词要比中文的分词效果要好，因为它能把语气词去掉，可能是因为中文太博大精深了，外国人学中文并不容易，所以当然做不好中文分词了。其他语言就不一一测试了，大家有兴趣可以自行测试看看效果。  
以上就是elasticsearch为我们提供的内置的分词器，通过它们的分词特点发现，它们对中文的分词效果都不好，那这样的话，我们就得看看是否有第三方分词器了，如果有的话，那这个分词器一定是中国人开发的，因为只有中国人才更理解中文的博大精深。
## 安装中文分词插件
那既然elasticsearch内置的分词组件都不是我们想要的效果，那我们就使用第三方的中文分词插件吧，经过了解，第三方中文插件有一个比较知名的，中文分词的效果也很好，它就是IKAnalyzer，是一个叫medcl的中国人开发的，那我们就马上把它装上去看看分词效果吧。
#### 下载IKAnalyzer插件
>IKAanlyzer下载地址为https://github.com/medcl/elasticsearch-analysis-ik/releases  

IKAnalyzer的版本会随着elasticsearch版本更新而更新，所以我们下载的版本最好与elasticsearch的版本一致，我们的elasticsearch的版本为6.2.4，所以我们IKAnalyzer也是下载6.2.4，并且我们要下载编译好的zip包，不要下载源码包，不然还得自己去编译，包的全名为elasticsearch-analysis-ik-6.2.4.zip。
#### 安装IKAnalyzer
1、进入elasticsearch安装目录下的plugins目录，创建ik目录
```
$ cd /usr/local/elasticsearch/plugins
$ mkdir ik
```
2、上传IKAnalyzer包，并解压
```
$ unzip elasticsearch-analysis-ik-6.2.4.zip  #解压出来的目录叫elasticsearch
$ cd elasticsearch #进入刚刚解压出来的elasticsearch目录
$ cp -r ./* /usr/local/elasticsearch/plugins/ik/  #拷贝当前目录所有子目录和文件到elasticsearch的ik目录下
```
#### 重启elasticsearch
*注意不要使用后台运行的当时启动，因为待会需要看控制台打印信息*  
![启动打印信息](https://upload-images.jianshu.io/upload_images/10574922-22a956172e913f40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
看到elasticsearch启动打印信息有加载IK分词器相关的消息就代表插件已经安装上去了。
#### 测试分词效果
那现在我们已经把IK分词器安装上去了，现在我们就来测试一下它的分词效果，IK分词器有两种分词效果，一种是ik_max_word（最大分词）和ik_smart（最小分词），我们分别用这两种分词来测试“中华人民共和国国歌”这个搜索关键词。  
我们先来看看最大分词效果，ik_max_word：  
![最大分词效果](https://upload-images.jianshu.io/upload_images/10574922-cbaf744edcc3781b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
很明显，这次的分词效果要比前面的任何一种elasticsearch内置的分词效果都要好很多，是有中文语义的分词，我们在来看看最小分词的效果，ik_smart：  
![最小分词效果](https://upload-images.jianshu.io/upload_images/10574922-ca41e50869da4e87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
最小分词就给我们把搜索关键词拆分成“中华人民公共国”和“国歌”这两个词元，从效果来看没有最大分词的效果好。我们再来看看使用IK分词对英文分词的支持如何：  
![使用IK分词器对英文分词](https://upload-images.jianshu.io/upload_images/10574922-8fc980c048d8969b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
效果还是可以的，会去掉像“A”这样单独存在没有意义的词元，而且我发现，它跟elasticsearch内置的english语言分词器对英文分词效果是一样的。  
那这样的话我们就确定了后面的分词器我们都IK分词器了，因为它对中文分词的效果正是我们想要的，而且它还对英文分词支持很好。




